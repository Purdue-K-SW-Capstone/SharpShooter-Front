{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87813226",
   "metadata": {},
   "source": [
    "# Collecting Face Images\n",
    "\n",
    "This code is for collecting face images to create dataset of the face recognition model with web cam.  \n",
    "If the specific face is collected, that face will get the authority to use the entire system.  \n",
    "There are some libraries to run this code on the first cell, please check it.   \n",
    "It is recommend to run the code with Jupyter Notebook. Run each cell in order.  \n",
    "\n",
    "- Recommend IDE: Jupyter Notebook, Visual Sutdio Code\n",
    "- Language: **Python 3.10**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160b750d",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af529416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Import haar cascade classifier from cv2 \n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c546b1",
   "metadata": {},
   "source": [
    "## 2. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e263f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect face on the image and return coordinates \n",
    "def detect_face(gray_img) :\n",
    "    # Set the detector function \n",
    "    coordinate = face_cascade.detectMultiScale( \n",
    "            gray_img,          # input grayscale image \n",
    "            scaleFactor=1.3,   # imgae pyramid scale \n",
    "            minNeighbors=5)    # neighbor object minimum distance pixels \n",
    "    \n",
    "    # Detect face coordinate location in image, i.e, detect face\n",
    "    # If the face was not detected, \n",
    "    if len(coordinate) == 0 : \n",
    "        return None\n",
    "    else : \n",
    "        # If faces were detected (two more), \n",
    "        if len(coordinate) == 2 :\n",
    "            x1,y1,w,h = coordinate[1].squeeze()\n",
    "        # If just one face was detected,\n",
    "        else : \n",
    "            x1,y1,w,h = coordinate.squeeze()         \n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2 = abs(x1+w)\n",
    "        y2 = abs(y1+h)\n",
    "    \n",
    "    return x1,y1,x2,y2 # coordinates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a721e36c",
   "metadata": {},
   "source": [
    "## 3. Start Collecting Face Dataset\n",
    "\n",
    "To collect dataset, just run below cell\n",
    "\n",
    "- to capture and make data, press '1'\n",
    "- to quit the code, press 'q' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a81443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images captured!\n"
     ]
    }
   ],
   "source": [
    "# Configuration: set the number of the image to collect and the root to store dataset \n",
    "path = os.getcwd()  # currnt path \n",
    "img_cnt = 1         # initial the number of image\n",
    "max_img = 300       # maximum number of image \n",
    "\n",
    "# Initialize the webcam \n",
    "video_capture = cv2.VideoCapture(0) # 0 is a default embedded camera\n",
    "\n",
    "while True:\n",
    "    # Read each frame from the webcam\n",
    "    _, frame = video_capture.read()\n",
    "    x, y, c = frame.shape\n",
    "    \n",
    "    # Flip the frame vertically\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # Convert the frame as grayscale\n",
    "    framegray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Extract a face coordinate from the frame and add text \n",
    "    coords = [] \n",
    "    coords = detect_face(framegray) \n",
    "    if coords is not None :\n",
    "        cv2.putText(frame, str(coords), (5,40), cv2.FONT_HERSHEY_PLAIN, 1, (200,200,0))\n",
    "    \n",
    "    # To capture the frame \n",
    "    if cv2.waitKey(1) == ord('1') :\n",
    "        img_name = path+\"\\\\Dataset\\\\FACE\\\\Dataset04\\\\id04_frame_{}.png\".format(img_cnt) # config\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        # If capture is successful\n",
    "        print(\"{} written!\".format(img_name)) \n",
    "        img_cnt += 1\n",
    "    \n",
    "    # To Quit from application, press \"q\"\n",
    "    if cv2.waitKey(1) == ord('q') or img_cnt == (max_img + 1) : \n",
    "        img_cnt -= 1\n",
    "        break\n",
    "        \n",
    "    # Show the final output\n",
    "    cv2.imshow(\"Output\", frame)\n",
    "    \n",
    "# Release the webcam and destroy all active windows\n",
    "print(\"{} images captured!\".format(img_cnt)) # Print how many images captured\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp",
   "language": "python",
   "name": "mp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
