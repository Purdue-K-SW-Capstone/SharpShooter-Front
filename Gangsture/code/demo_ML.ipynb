{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d93d273",
   "metadata": {},
   "source": [
    "# Demo Code with ML\n",
    "\n",
    "(10/27/2022) 1st version completed \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160b750d",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af529416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeaf5975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtang\\anaconda3\\envs\\mp\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "C:\\Users\\mtang\\anaconda3\\envs\\mp\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split # Helps with organizing data for training\n",
    "from sklearn.metrics import confusion_matrix # Helps present results as a confusion-matrix\n",
    "\n",
    "# Import of keras model and hidden layers for convolutional network\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "# Model\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import plot_importance \n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c574a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "path = os.getcwd()\n",
    "model = pickle.load(open(path + '/Model/1025model_xgb.h5', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e062c",
   "metadata": {},
   "source": [
    "## Prepare Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f07094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for bounding rectangle\n",
    "def calc_bounding_rect(image, landmarks): # Calculate bounding rectangle \n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "    x, y, w, h = cv2.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "\n",
    "def draw_bounding_rect(use_brect, image, brect): # Draw bounding rectangle\n",
    "    if use_brect:\n",
    "        cv2.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
    "                     (0, 0, 0), 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "648d9291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessed_data(data) :\n",
    "    # drop unnecessary column: landmark\n",
    "    data = data.drop([0], axis=1)\n",
    "        \n",
    "    # mapping hand position: right, left \n",
    "    data[1] = data[1].replace({'Right': 0, 'Left': 1})\n",
    "    \n",
    "    # rename columns \n",
    "    data.columns = [\"hand_type\", \"1_x\", \"1_y\", \"1_z\", \"1_rx\", \"1_ry\", \"1_rz\"]\n",
    "    \n",
    "    # add new columns \n",
    "    new_cols = []\n",
    "    for i in range(2, 22) :\n",
    "        new_cols = new_cols + [str(i)+\"_x\", str(i)+\"_y\", str(i)+\"_z\", str(i)+\"_rx\", str(i)+\"_ry\", str(i)+\"_rz\"]\n",
    "    data[new_cols] = \"\"\n",
    "    #data = pd.concat([data, data_new])\n",
    "    \n",
    "    # insert values at new columns \n",
    "    for j in range(1, 21) :\n",
    "        col_list = []\n",
    "        col_list = [str(j+1)+\"_x\", str(j+1)+\"_y\", str(j+1)+\"_z\", str(j+1)+\"_rx\", str(j+1)+\"_ry\", str(j+1)+\"_rz\"]\n",
    "        data.loc[0, col_list] = data.loc[j, [\"1_x\", \"1_y\", \"1_z\", \"1_rx\", \"1_ry\", \"1_rz\"]].values\n",
    "            \n",
    "    # remove all rows except for the first row  \n",
    "    remove_idx = []\n",
    "    for i in range (1, 21) : \n",
    "        remove_idx.append(i)\n",
    "    data = data.drop(data.index[remove_idx]).reset_index(drop=True)\n",
    "\n",
    "    # convert dtypes \n",
    "    data = data.astype(float)\n",
    "    \n",
    "    return data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a721e36c",
   "metadata": {},
   "source": [
    "## Start Camera with ML\n",
    "To test demo code with Machine Learning\n",
    "\n",
    "- to quit the code, press 'q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59e70b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting for Mediapipe \n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1,              # only two hand detected \n",
    "                       min_detection_confidence=0.7) # defualt 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a438e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize for datasets \n",
    "img_cnt = 1\n",
    "landmarks = []\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Initialize the webcam \n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read each frame from the webcam\n",
    "    _, frame = video_capture.read()\n",
    "    x, y, c = frame.shape\n",
    "    \n",
    "    # Flip the frame vertically\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    result = hands.process(framergb)\n",
    "    if result.multi_hand_landmarks:\n",
    "        for handslms, handness in zip(result.multi_hand_landmarks, \n",
    "                                      result.multi_handedness): \n",
    "            landmarks.clear() # for empty list \n",
    "            for point in mp_hands.HandLandmark: # 0 ~ 20\n",
    "                x = handslms.landmark[point].x\n",
    "                y = handslms.landmark[point].y\n",
    "                z = handslms.landmark[point].z\n",
    "                landmarks.append([str(point), handness.classification[0].label, x, y, z])\n",
    "            \n",
    "            # Drawing landmarks on frames with bounding rectangle\n",
    "            #brect = calc_bounding_rect(frame, handslms)\n",
    "            #frame = draw_bounding_rect(True, frame, brect)\n",
    "            mp_drawing.draw_landmarks(frame, handslms, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "    # create realtive coordinates  \n",
    "    df = pd.DataFrame(landmarks)\n",
    "    relative_df = pd.DataFrame()\n",
    "    base_lm = df.iloc[0, 2:].astype(float)\n",
    "    for i in range(0, 21) :\n",
    "        target_lm = df.loc[i, 2:].values.astype(float)\n",
    "        result_lm = target_lm-base_lm\n",
    "        relative_df = relative_df.append(pd.DataFrame(result_lm).transpose(), ignore_index=True)\n",
    "    new_df = pd.concat([df, relative_df], axis=1)\n",
    "    \n",
    "    # preprocessing for input dataset \n",
    "    processed_df = preprocessed_data(new_df)\n",
    "    \n",
    "    # input data to machine learning\n",
    "    X = np.array(processed_df)\n",
    "    #X = X.reshape(1, 300, 300, 1)\n",
    "    pred_proba = model.predict_proba(X)\n",
    "    prediction = np.argmax(pred_proba)\n",
    "    cv2.putText(frame, str(prediction), (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # To Quit from application, press \"q\"\n",
    "    if cv2.waitKey(1) == ord('q'): \n",
    "        img_cnt -= 1\n",
    "        break\n",
    "        \n",
    "    # Show the final output\n",
    "    cv2.imshow(\"Output\", frame)\n",
    "    \n",
    "# release the webcam and destroy all active windows\n",
    "print(\"{} images captured!\".format(img_cnt))\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99bf274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check one more time, perfect\n",
    "pred_proba = model.predict_proba(X)\n",
    "prediction = np.argmax(pred_proba)\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp",
   "language": "python",
   "name": "mp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
